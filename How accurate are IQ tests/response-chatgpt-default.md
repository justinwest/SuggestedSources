<!-- 
Generated by: chatgpt
Model: o3
Prompt type: default
Generated at: 2025-06-10T20:22:04.741376
-->

*This response was generated by **ChatGPT** (o3) without using external sources.*

[← Back to Question README](README.md) | [← Back to Index](../README.md)

*Want to add more sources or suggest new questions? [Contribute on GitHub](https://github.com/justinwest/SuggestedSources)*

---

# How accurate are IQ tests?

How Accurate Are IQ Tests? – A Detailed Appraisal
──────────────────────────────────────────────────

1. What “accuracy” means in psychometrics  
   • Reliability – Does the test give you the same score (within a small margin) when nothing important has changed?  
   • Validity – Does the test actually measure the construct it claims to measure (“general cognitive ability”, “g”) and can it predict things it is supposed to predict (grades, job performance, etc.)?  
   • Standard error of measurement (SEM) – How wide is the confidence band around any single score?  
   • Fairness – Is the test equally valid for people of different cultural, linguistic, or socioeconomic backgrounds?

2. State-of-the-art reliability  
   Modern individually administered batteries (e.g., Wechsler-IV/V, Stanford-Binet-5, WJ-IV) report:  
   • Internal-consistency α or split-half r ≈ .95–.98 for Full-Scale IQ  
   • Test-retest r ≈ .90–.95 over weeks or months (longitudinal stability drops slightly over years, especially in childhood because true ability is still developing).  
   • Typical SEM ≈ 2.5–3.5 points. Therefore, a score of 100 usually means “true” ability is somewhere between ~94 and 106 (68 % CI) or ~91 and 109 (95 % CI).

3. Construct and criterion validity  
   a. Convergent/construct validity  
      – IQ tests inter-correlate strongly (r ≈ .60–.90) despite differing item formats.  
      – Factor analyses consistently extract a dominant g factor that explains ~40–50 % of variance.  
   b. Predictive (criterion) validity  
      – School grades: r ≈ .50–.70 (highest with math and science achievement).  
      – Years of education: r ≈ .55.  
      – Occupational status: r ≈ .40–.50.  
      – Job performance (supervisory ratings): r ≈ .35; with work-sample tests: r ≈ .55.  
      – Income (adult): r ≈ .30; risk of unemployment or welfare: negative correlations of similar magnitude.  
      – Health-related outcomes and longevity: small-to-moderate correlations (r ≈ .15–.25).  
      – Criminality: inverse correlations (r ≈ –.19 to –.30).  
   Meta-analyses show these relations hold across cohorts and continents, but predictive power is never perfect—non-cognitive variables (personality, grit, social capital, luck) also matter.

4. Domain coverage and what IQ does *not* measure well  
   • Creativity, practical know-how, social or emotional intelligence, specific subject knowledge, artistic talent, wisdom, and moral reasoning are poorly covered.  
   • Extremely high or low ends can suffer from ceiling or floor effects unless a specialized form (e.g., SB-5 Extended Battery) is used.  

5. Contextual and situational influences  
   • Test familiarity/practice: gains of 2–7 points from retesting are common.  
   • Health, fatigue, anxiety, hunger, and acute stress can depress scores.  
   • Motivation and financial incentives can raise scores—1–10 points in experiments.  
   • Language proficiency can confound verbal subtests; non-verbal tools (Raven’s, Cattell Culture-Fair) mitigate but do not eliminate this issue.

6. Cultural and socioeconomic fairness  
   • Modern norms stratify samples by gender, ethnicity, region, and parental education to reduce bias.  
   • Differential-item-functioning studies show relatively few items with large bias; deleting them changes group mean differences little.  
   • Mean gaps (e.g., ~1 SD Black–White in U.S., ~0.3–0.5 SD low- vs high-SES) exist but appear in *most* cognitively loaded tasks, not just formal IQ tests, implying they are not purely artefacts of biased content.  
   • Stereotype-threat and test anxiety can account for small portions (≈ 0–0.2 SD) of group differences.

7. Individual vs. group prediction  
   • Correlations of .50 explain 25 % of the variance: good for group-level forecasting (e.g., HR selection, epidemiology) but leave large uncertainty for any single person.  
   • A 110 IQ student can outscore a 130 IQ peer in math or career success; distributions overlap.

8. Special uses and diagnostic cut-offs  
   • Intellectual disability: IQ < 70 (±5) plus adaptive impairments.  
   • Gifted programs: often > 130 (top 2 %).  
   • Neuropsychological assessment: compare current IQ with premorbid estimates to infer injury impact.

9. Alternative and expanded views  
   • Multiple-intelligences, triarchic, and dynamic-assessment models critique g-centric testing, but empirical support for replacing IQ with these frameworks is modest.  
   • Combining IQ with measures of executive function, working memory, or broad achievement yields slightly better prediction of school success.  

10. Bottom-line assessment  
   • Reliability: very high (comparable to leading psychological instruments and higher than many medical lab tests).  
   • Validity: moderate-to-high for academic and many life outcomes; lower for creativity, interpersonal skill, and real-world wisdom.  
   • Precision: ±5–6 points covers 95 % of measurement error. Scores across well-normed tests generally differ by < 7 points.  
   • Fairness: continually improving but not immune to socio-cultural influences; IQ tests mirror, more than cause, societal inequalities.  

Key take-away: An IQ test is a highly reliable ruler for a *particular* slice of mental performance—general cognitive problem-solving under time-limited, decontextualized conditions. It is the single best quantified predictor we have for certain outcomes, yet it is neither an all-purpose talent gauge nor a fixed destiny. Interpret any score as a range, integrate it with broader information, and apply it only to decisions for which its predictive validity has been demonstrated.